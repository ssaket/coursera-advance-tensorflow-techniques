{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from custom_data import CustomDataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"torronto_df.csv\")\n",
    "df.output = df.output.astype(np.int32)\n",
    "df.center_index = df.center_index.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_file</th>\n",
       "      <th>fixation_file</th>\n",
       "      <th>image_size</th>\n",
       "      <th>center_index</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/toronto/fixdens/images/1.jpg</td>\n",
       "      <td>data/toronto/fixdens/output/d1.jpg</td>\n",
       "      <td>(681, 511)</td>\n",
       "      <td>[376, 367]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/toronto/fixdens/images/1.jpg</td>\n",
       "      <td>data/toronto/fixdens/output/d1.jpg</td>\n",
       "      <td>(681, 511)</td>\n",
       "      <td>[380, 351]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>data/toronto/fixdens/images/1.jpg</td>\n",
       "      <td>data/toronto/fixdens/output/d1.jpg</td>\n",
       "      <td>(681, 511)</td>\n",
       "      <td>[375, 349]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data/toronto/fixdens/images/1.jpg</td>\n",
       "      <td>data/toronto/fixdens/output/d1.jpg</td>\n",
       "      <td>(681, 511)</td>\n",
       "      <td>[383, 351]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>data/toronto/fixdens/images/1.jpg</td>\n",
       "      <td>data/toronto/fixdens/output/d1.jpg</td>\n",
       "      <td>(681, 511)</td>\n",
       "      <td>[375, 351]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         image_file  \\\n",
       "0           0  data/toronto/fixdens/images/1.jpg   \n",
       "1           1  data/toronto/fixdens/images/1.jpg   \n",
       "2           2  data/toronto/fixdens/images/1.jpg   \n",
       "3           3  data/toronto/fixdens/images/1.jpg   \n",
       "4           4  data/toronto/fixdens/images/1.jpg   \n",
       "\n",
       "                        fixation_file  image_size center_index  output  \n",
       "0  data/toronto/fixdens/output/d1.jpg  (681, 511)   [376, 367]       1  \n",
       "1  data/toronto/fixdens/output/d1.jpg  (681, 511)   [380, 351]       1  \n",
       "2  data/toronto/fixdens/output/d1.jpg  (681, 511)   [375, 349]       1  \n",
       "3  data/toronto/fixdens/output/d1.jpg  (681, 511)   [383, 351]       1  \n",
       "4  data/toronto/fixdens/output/d1.jpg  (681, 511)   [375, 351]       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= df.sample(frac=0.7,random_state=200) #random state is a seed value\n",
    "test= df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "target_size = (400,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = CustomDataGen(train,\n",
    "                             X_col={\n",
    "                                 'path': 'image_file',\n",
    "                                 'center': 'center_index'\n",
    "                             },\n",
    "                             y_col={\n",
    "                                 'output': 'output'\n",
    "                             },\n",
    "                             batch_size=batch_size,\n",
    "                             input_size=target_size)\n",
    "valgen = CustomDataGen(test,\n",
    "                             X_col={\n",
    "                                 'path': 'image_file',\n",
    "                                 'center': 'center_index'\n",
    "                             },\n",
    "                             y_col={\n",
    "                                 'output': 'output'\n",
    "                             },\n",
    "                             batch_size=batch_size,\n",
    "                             input_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = traingen[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_base_network(stream_name, patch_size=(42,42,3)):\n",
    "    input = Input(shape=(patch_size), name='patch_input')\n",
    "    x = Conv2D(96, 7, activation='relu', name='conv_1')(input)\n",
    "    x = MaxPool2D((2, 2))(x)\n",
    "    x = Conv2D(160, 3, activation='relu', name='conv_2')(x)\n",
    "    x = MaxPool2D((2, 2))(x)\n",
    "    x = Conv2D(288, 3, activation='relu', name='conv_3')(x)\n",
    "    x = MaxPool2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu', name='dense_stream')(x)\n",
    "    return Model(inputs=input, outputs=x, name=stream_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_1 = Input(shape=(\n",
    "    42,\n",
    "    42,\n",
    "    3,\n",
    "), name='input_img_1')\n",
    "stream_s1 = initialize_base_network(stream_name='stream_1')\n",
    "vec_output_a = stream_s1(input_image_1)\n",
    "\n",
    "input_image_2 = Input(shape=(\n",
    "    42,\n",
    "    42,\n",
    "    3,\n",
    "), name='input_img_2')\n",
    "stream_s2 = initialize_base_network(stream_name='stream_2')\n",
    "vec_output_b = stream_s2(input_image_2)\n",
    "\n",
    "input_image_3 = Input(shape=(\n",
    "    42,\n",
    "    42,\n",
    "    3,\n",
    "), name='input_img_3')\n",
    "stream_s3 = initialize_base_network(stream_name='stream_3')\n",
    "vec_output_c = stream_s3(input_image_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = Add(name='add_streams')([vec_output_a, vec_output_b, vec_output_c])\n",
    "x = Dense(512, activation='relu', name='dense_all')(added)\n",
    "output = Dense(1, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_image_1, input_image_2, input_image_3], output, name='mr-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mr-cnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img_1 (InputLayer)       [(None, 42, 42, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_img_2 (InputLayer)       [(None, 42, 42, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_img_3 (InputLayer)       [(None, 42, 42, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " stream_1 (Functional)          (None, 512)          1895232     ['input_img_1[0][0]']            \n",
      "                                                                                                  \n",
      " stream_2 (Functional)          (None, 512)          1895232     ['input_img_2[0][0]']            \n",
      "                                                                                                  \n",
      " stream_3 (Functional)          (None, 512)          1895232     ['input_img_3[0][0]']            \n",
      "                                                                                                  \n",
      " add_streams (Add)              (None, 512)          0           ['stream_1[0][0]',               \n",
      "                                                                  'stream_2[0][0]',               \n",
      "                                                                  'stream_3[0][0]']               \n",
      "                                                                                                  \n",
      " dense_all (Dense)              (None, 512)          262656      ['add_streams[0][0]']            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            513         ['dense_all[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,948,865\n",
      "Trainable params: 5,948,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,\n",
    "                   loss=bce,\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "(484, 484, 3) 589 157 [ 73 505]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: height must be >= target + offset.\nTraceback (most recent call last):\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 75, in __getitem__\n    X, y = self.__get_data(batches)\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in __get_data\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in <listcomp>\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 45, in __get_input_img\n    image_arr = tf.image.crop_to_bounding_box(image_arr, ymin, xmin, h, w).numpy()\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\", line 81, in _assert\n    raise ex_type(msg)\n\nValueError: height must be >= target + offset.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_6]]\n  (1) INVALID_ARGUMENT:  ValueError: height must be >= target + offset.\nTraceback (most recent call last):\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 75, in __getitem__\n    X, y = self.__get_data(batches)\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in __get_data\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in <listcomp>\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 45, in __get_input_img\n    image_arr = tf.image.crop_to_bounding_box(image_arr, ymin, xmin, h, w).numpy()\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\", line 81, in _assert\n    raise ex_type(msg)\n\nValueError: height must be >= target + offset.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2676]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13656\\3577735682.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraingen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\tflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: height must be >= target + offset.\nTraceback (most recent call last):\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 75, in __getitem__\n    X, y = self.__get_data(batches)\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in __get_data\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in <listcomp>\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 45, in __get_input_img\n    image_arr = tf.image.crop_to_bounding_box(image_arr, ymin, xmin, h, w).numpy()\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\", line 81, in _assert\n    raise ex_type(msg)\n\nValueError: height must be >= target + offset.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_6]]\n  (1) INVALID_ARGUMENT:  ValueError: height must be >= target + offset.\nTraceback (most recent call last):\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 75, in __getitem__\n    X, y = self.__get_data(batches)\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in __get_data\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 62, in <listcomp>\n    X1_batch = np.asarray([self.__get_input_img(x, y, (400,400)) for x, y in zip(path_batch, center_loc_batch)])\n\n  File \"c:\\Users\\sktsa\\Projects\\coursera-advance-tensorflow-techniques\\test\\custom_data.py\", line 45, in __get_input_img\n    image_arr = tf.image.crop_to_bounding_box(image_arr, ymin, xmin, h, w).numpy()\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\sktsa\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\", line 81, in _assert\n    raise ex_type(msg)\n\nValueError: height must be >= target + offset.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2676]"
     ]
    }
   ],
   "source": [
    "model.fit(traingen, validation_data=valgen, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = traingen[14]\n",
    "model.predict_step((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cfb9b8fc2aa05cd2f03010444f4bf2bf517d2be05582e3f9faf36ad25271df3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
